
**Zsolt Talata** Chair  
University of Kansas  

Tuesday, Aug 6: 10:30 AM - 12:20 PM  
5105 Contributed Papers 

Oregon Convention Center 

Room: CC-C121 

#### Main Sponsor

Section on Statistical Learning and Data Science

## Presentations

### [A New RNN Model for American Sign Language Data](https://ww3.aievolution.com/JSMAnnual2024/Events/viewEv?ev=3532 "A New RNN Model for American Sign Language Data")

Millions of people worldwide suffer from some type of disability that prevents them from expressing themselves or communicating with others. Thus, a parsimonious attention-based model was created to bridge the language barrier for those reliant on American Sign Language (ASL) and address the sign language recognition issue through the creation of a novel neural network-based ASL translator based on the How2Sign dataset, consisting of a parallel corpus of more than 80 hours of sign language videos. Unlike existing projects, this proposed RNN was crafted using a sequence of recurrent layers using training, testing, validation sets and cross validation. Model performance evaluation metrics include accuracy, sensitivity, specificity and F1 score. By taking RGB-D images as input and using segmentation methods, the model has succeeded in tasks like image captioning and action recognition, achieving a higher accuracy range than existing methods. The results ultimately demonstrate this RNN's potential utility for daily use, communication, and promising use on edge devices. 

#### Keywords

Attention-based model  
  
American Sign Language  
  
How2Sign Dataset  
  
deep learning  
  
on-device learning  
  
RGB-D images 

  

  

#### First Author

_Anna Wang_  

#### Presenting Author

_Anna Wang_  

---

### [Advanced RNBRW-Based Testing for Community Structure Significance in Networks](https://ww3.aievolution.com/JSMAnnual2024/Events/viewEv?ev=3533 "Advanced RNBRW-Based Testing for Community Structure Significance in Networks")

This research develops an innovative goodness-of-fit test for detecting community structures in networks, utilizing eigenvalue distributions of a normalized, Renewal Non-Backtracking Random Walk (RNBRW)-weighted adjacency matrix. Our method, diverging from traditional techniques, emphasizes network cyclic structures and graph weighting. We aim to enhance detection accuracy by analyzing the largest singular value of the normalized and weighted adjacency matrix obtained through RNBRW. Central to our methodology are Monte Carlo simulations, generating empirical distributions of the test statistic under varying hypotheses. The proposed test leverages eigenvalue distributions from the RNBRW-derived matrix to exploit asymptotic behaviors in the absence of community structures. Our comprehensive approach includes assessing Type I and II error rates, ensuring reliability under different network conditions. This research itegrates RNBRW with advanced statistical inference to create a sophisticated, scalable tool for validating community structures, thereby advancing network analysis and graph data science. 

#### Keywords

RNBRW  
  
Network inference  
  
Network data analysis  
  
Community structure 

  

  

#### Co-Author

_Michael Higgins_, Kansas State University  

#### First Author

_Behnaz Moradijamei_, James Madison University  

#### Presenting Author

_Behnaz Moradijamei_, James Madison University  

---

### [Bridging latent space models and classic network frameworks](https://ww3.aievolution.com/JSMAnnual2024/Events/viewEv?ev=3536 "Bridging latent space models and classic network frameworks")

Classic network models, such as the Erdös-Rényi or stochastic blockmodel, are cornerstones of network science, but struggle to accurately model real-word data. Alternatives, such as latent space modeling, may be attractive options for complex data. Yet, research connecting the various approaches is limited. We propose an innovative approach that leverages simple latent space modeling to create analogs of classic network models which integrate transitivity and community structure while remaining adaptable and interpretable. Our approach extends beyond traditional latent space modeling by providing comprehensive comparisons to simple models, allowing for tailored adjustments of network structure while preserving essential characteristics, such as degree distribution. We emphasize the impact of latent space topology and dimensionality, and demonstrate the influence of latent space choice on the relationship between transitivity and degree distribution in the resulting network. These findings expand our understanding of network modeling and offer a useful bridge between the simplicity of classic models with more complex, but data-appropriate mechanistic or latent space models. 

#### Keywords

Networks  
  
Network science  
  
Methods  
  
Latent space modeling  
  
Classic network modeling 

  

  

#### Co-Author

_Jukka-Pekka Onnela_  

#### First Author

_Emma Crenshaw_  

#### Presenting Author

_Emma Crenshaw_  

---

### [Studying Social Network Dynamics: Addressing Aggregation Challenges and Modeling Language Risk](https://ww3.aievolution.com/JSMAnnual2024/Events/viewEv?ev=3534 "Studying Social Network Dynamics: Addressing Aggregation Challenges and Modeling Language Risk")

A key challenge of performing inference and other statistical analyses on social networks is limited data availability. One approach for addressing this problem is to gather data from several similarly situated communities in an attempt to study the aggregate properties of the networks. For example, researchers interested in school children may collect network data from several classrooms within the same school to study the relationship between network effects and learning outcomes. However, this aggregation approach introduces its own challenges, as the distributions of network metrics and dependent variables of interest may not be heterogeneously distributed. In this talk, I present methodological and theoretical analysis of this problem, motivated by real-world data collected to measure language development by Broda et al. (2023), including a multilevel model approach (Chow, 2022) for centrality scores and a related sensitivity analysis addressing the consistency of aggregation results. I will also discuss an extension that incorporates network embeddings, using spectral and graph-based neural network outputs as covariates to predict language development outcomes. 

#### Keywords

Social Network Analysis  
  
Aggregation  
  
Modeling Language Risk  
  
Network Embedding  
  
Graph Neural Network 

  

  

#### Co-Author

_Daryl DeFord_, Washington State University  

#### First Author

_Md Mahedi Hasan_, Washington State University  

#### Presenting Author

_Md Mahedi Hasan_, Washington State University  

---

### [Modeling Hypergraphs Using Non-symmetric Determinantal Point Processes](https://ww3.aievolution.com/JSMAnnual2024/Events/viewEv?ev=3535 "Modeling Hypergraphs Using Non-symmetric Determinantal Point Processes")

Conventional statistical network modeling typically focuses on interactions between pairs of individuals. However, in many real-world applications, interactions often involve multiple entities. To model various types of hypergraphs without limitations on the cardinality and multiplicity of hyperedges, we propose a latent space model for hypergraphs, using a non-symmetric determinantal point process (DPP). Unlike existing hypergraph models that are driven solely by either similarity or diversity among nodes, our adjusted non-symmetric DPP structure allows for both repulsive and attractive interactions between nodes, as well as accounting for the popularity of each node. Our model also accommodates various types of hypergraphs without limitations on the cardinality and multiplicity of hyperedges. For parameter estimation, we employ the Adam optimization in conjunction with maximum likelihood estimation. We have established the consistency and asymptotic normality of these maximum likelihood estimators. The proof is non-trivial due to the unique configuration of the parameter space. Simulation studies support the effectiveness of our method. Moreover, we have applied our model to several real-world datasets, demonstrating its ability to make prediction for hyperedges. 

	![[Hypergraph-wikipedia.svg.png]]
#### Keywords

hypergraph embedding  
  
determinantal point process  
  
latent space  
  
network analysis  
  
asymptotic normality 

  

  

#### Co-Author(s)

_Emma Jingfei Zhang_, Emory University  
_Ji Zhu_, University of Michigan  

#### First Author

_Yichao Chen_  

#### Presenting Author

_Yichao Chen_  

---

### [Natural Covariate-adjusted Graphical Regression](https://ww3.aievolution.com/JSMAnnual2024/Events/viewEv?ev=3537 "Natural Covariate-adjusted Graphical Regression")

Gaussian graphical models (GGMs) are widely used for recovering the conditional independence structure among random variables. Several recent advances have been made to exploit an additional set of variables for better estimating the GGMs of the variables of interest. For example, in co-expression quantitative trait locus (eQTL) studies, both the mean expression level of genes as well as their pairwise conditional independence may be adjusted by genetic variants along the DNA sequence. Existing methods in this covariate-adjusted GGM either focus solely on estimating the mean expression level adjustment, or suffer from poor scaling assumptions due to the inherent non-convexity of the simultaneous estimation of the mean and precision matrix. We propose a convex formulation that jointly estimates the covariate-adjusted mean and precision matrix by utilizing the natural parametrization of the multivariate Gaussian likelihood. The convexity yields theoretically better performance as the sparsity and dimension of the covariates grows large relative to the number of samples. We verify our theoretical results with numerical simulations and perform a reanalysis of a brain cancer eQTL study. 

#### Keywords

Graphical models  
  
High-dimensional statistics  
  
Covariance estimation  
  
Sparse-group lasso  
  
Co-expression QTL 

  

  

#### Co-Author

_Guo Yu_, University of California Santa Barbara  

#### First Author

_Ruobin Liu_, University of California, Santa Barbara  

#### Presenting Author

_Ruobin Liu_, University of California, Santa Barbara  

---