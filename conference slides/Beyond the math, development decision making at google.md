 

# Beyond the Math: Development and Decision Making at Google

**Susheela Singh** Chair  
Google  

**Susheela Singh** Organizer  
Google  

**YunChu Huang** Organizer  
Google  

**Tanvi Chheda** Organizer  

Wednesday, Aug 7: 2:00 PM - 3:50 PM  
1692 Topic-Contributed Paper Session 

Oregon Convention Center 

Room: CC-E146 

  

#### Applied

Yes

#### Main Sponsor

Section on Statistical Computing

#### Co Sponsors

Section on Statistical Learning and Data Science

## Presentations

## [Data Ethics](https://ww3.aievolution.com/JSMAnnual2024/Events/viewEv?ev=2475 "Data Ethics")

Many statistically valid approaches can lead to different conclusions - like a regression analysis can show a positive correlation on the same data set that contains a Simpson's paradox and a clear subset of the population showing a negative correlation. Often, it comes down to the ethics of the data scientist leading the analysis which result is the one that makes it to the final result. We'll cover many of these statistical gotchas, career enders, and difficult decisions that we as data scientists make every day in our jobs and guidance on what the ethical path looks like.  

#### Speaker

_Lois Smith_, Google  

### Notes

What does ethical transparency look like?

is your result repeatable?
could someone else follow your wokr?

is your result understandable by most?
- can your plot be understood without you explaining it
- is it easy to understand the takeaway

is you result clear?
- could your result interpreted differently by different views 
- is it glaringly obvious?

vega_dataset car

good example of statment X% reduction from 1970 to 1980, shows a plot of the mean, has variablity,
shows scatter plot of all dta, shows box and whisker,
which is right?

there isnt a right answer

ethical data science is how do you help peopel come toa fair conclusion

How to be more transparent

keep it simple as possible, aim for up and to the left plots when possible, if there is significant variablity in the data, show it, either by shading

avoid trend lines, can be misleading, overdensescatter plots are not showing all of thedata 

correlation is not a substitute for showing data, p value isnt rock solid either

What does integrity look like?

will you admit when you are wrong?
- how you admit you are wrong matters too
seek review and feedback
- not all feedback is correct, if its repeated feedback, take note
- approach review with empathy
Is this the way you would want data presnted?
- balance between what is easiest to understand from a non-dat scientist perspective, what would convice you?

"if i just smoothed this a bit it would show the downward trend of the data better"


If you need to correct a result
1 leave a paper trail, link on your previous results to the new updated results and clearly state if there has been a correcetion

2 say it clearly, send an update to all partners thatyou have sent the previous result to. Explain in short clear language why the previous result is wrong and why the new one should be used

3 dont cry wolf, aim to have your work reviewed by yourself 


Accountability

Own your mistakes and successes
- build trust with aprtners and team, by not blaming others. if its your analysis you are responsible for ensuring data quality

Review others work as if it were your own
- excessive review is demoralizing and cruel, review with empathy and necessity, indentyify iwhen someth is a nit versus essential
- cursory reviews (juststamp it) are just a cruel, also means you share in the later mistakes or misinterpretations of the reuslts

Own your work
- if you see your result being misues or misrepresented, ask for your name to be reviewed

Example of accounatability, saying no
asume best intent, discuss calmly with a partner thattheir alterations do not reflect acurratley

reiterate inaccuracy, if they counter its whatthey need, explain its not accurate and why

protect your reputation, if you  can not get themto alter the chart, ask to have it removed from the presentation
surfaceto your manager immediately that this is happenign and show the example

remove yourself
if it is your manager doing this, find a new manager swiftyl or report to ethics board


How to be ethical data science

aim for clairt and readability rather than advanced stats
review others work as if it was your own
seek out thorough and comprehensive review of your own work, learn grow admit mistakes
aim to show a concise and complete summary of the data rather than get a point across 

Someone mentions public good is important, she mentiosn canadian ethics standard includes, does this data collection or result support candaians


---
this speaker couldnt make it
## [Amplify Your Impact as an Analyst](https://ww3.aievolution.com/JSMAnnual2024/Events/viewEv?ev=2474 "Amplify Your Impact as an Analyst")



The ability to extract insights from data is only half the battle for Product Analysts. Being able to effectively communicate those insights to the right group of people at the right time is what drives meaningful action and impact.  
  
In this talk we will discuss how to transition from a reactive role of fulfilling ad-hoc requests to becoming a trusted strategic advisor. Analysts typically have the most holistic view across products and as "bearers of truth", they have a key role to play in bringing teams together to drive action. Specifically, we will talk about identifying the right stakeholders, building strong relationships across products and collaborating effectively to position yourself in a strategic capacity. We will go over some projects at Google where Analysts are driving product change, discuss practical tips that you can start using today and some longer term strategies you can use to maximize the impact of your analytics work. 

  

#### Speaker

_Mehroze Munawar_, Google  



---

## [Building a Data Science Team](https://ww3.aievolution.com/JSMAnnual2024/Events/viewEv?ev=2476 "Building a Data Science Team")

Data Scientists are brought in at varying stages of broader team and organizational maturity. Sometimes, analytical questions are handled by data-savvy Product Managers and/or Engineers before they even consider formally including analysts. We'll introduce some best case practices and working models for new analytics teams that can scale and not get trapped in reactive ad-hoc questions cycles. We'll also go over how to balance driving data decision making while also investing in the development of a growing team of Data Scientists.  
 

  

#### Speaker

_Eva Roa_, Google  

led a google ads data scientist team, and an ny times built the first product analyst

TLDR: set data science up for success
1 understand DS value, make better decisions with data 
2 choose the right projects to asnwer core business questions (and learn to say no)

the problem, theres so little time and only so many data scineitist, but infiintie questions and often asked at last minute

if you focus on the wrong things, youll get stuck in a reactive ad-hoc cycle feeling like you and ypur team is underutilized and undervalued

the dream, high performaing well respeted DS team 

Cool impactful projects, team works on value projects that influence strategy
happy DS, feel fulfilled and produ of the work
seat at the table

Why do teams bring in data science,
Usually brought in after the project
Why: Mbetter decision making with data

think of your team as hub and spoje model. you are repsonsible for DS success and understand the value your team brings

You cant do it all, so how do you choose? make time for some important things and help short andlong term success

2 slides

Analytics maturity identify wher eyou are in all buckets of analtys maturaity, pick only one area to develop at a time 
slide


Team performance, you are only as good as your team, keep them happy, choose the most annoying/complained about things to address first
create a list of potential things your team could be doing
have a retro with your team ot indentify what is challenging or could be better on your team (start/stop/condinue)
basedon badnwidth, pick at least one thing to make better for oyur team

Note: process/norms are only useful an will only have sticking power if they address an actualneed, things function without them. They are extremely annoying overhead if ther arent implemented carefully, youll probably get it wrong the first time

Example team norms and proces projects
- onboarding docs
- intake proces
- sproject management process
- internal team site/repo
- code standards and review process
- mentorship
- tech leads
- analysis review process
- team rituals (meeting cadences)

Working Models Slide 

---

##  [Revisit model framework to measure and forecast user growth](https://ww3.aievolution.com/JSMAnnual2024/Events/viewEv?ev=2478 "Revisit model framework to measure and forecast user growth")

We introduce a novel framework for measuring and forecasting user growth through a revisit model. Common user growth metrics such as retention, L28, DAU, and MAU inevitably discard part of information in longitudinal activity patterns due to aggregation at the user level. Our framework leverages additional information present in longitudinal user logs to create revisit curves, thus providing richer insights. We have found that the typical revisit curves shape can best be described by involving distinct active and dormant user latent states. Transition rates between these states, derived from the shape of the revisit curves, serve as insightful metrics for understanding the impact of experiments on user engagement. Our preliminary findings suggest that short-term changes in these transition rates can predict the long-term impact of experiments on user growth. This method, applicable across various definitions of user activity, shows promise for broader application in understanding user growth across different product domains. 

  

#### Co-Author(s)

_Ark Fang_, Google  
_Daniel Persival_, Google LLC  

#### Speaker

_Anatoly Zaytsev_, Google LLC  
used math modeling for protein modeling
worked at aviation tech startup, currently he leveraged modeing to analyze user behavior patterns

## Notes

Works in google play store

measure impact of experiemnt of user engagement patterns?
slide

slide

alot of metrics lose information

revisit curves contatin rich information abotu user' activity patterns
(fraction of blue boces in a column)

return curve, its the minimal required complexity to model user behavior

instead of using all 4 parameters, it can be descrived as 2, freuqency of engagment, short term active inactive. Second paramter is visit consitency, captures transition between dormant and active state




---

### [Data Science Technical Skills for Careers in Industry](https://ww3.aievolution.com/JSMAnnual2024/Events/viewEv?ev=2477 "Data Science Technical Skills for Careers in Industry")

The field of data science is rapidly growing and expanding to cover more applications as well as a more diverse range of technical skills. While there are many positive aspects to this, it does mean that it can be increasingly challenging now for data scientists to understand what open roles in industry are best suited for their own specific technical skills and expertise. In parallel, it can be difficult for employers to communicate to candidates which skills are essential for their open roles, and even more difficult to quantify exactly how strong a candidate must be with respect to those skills to consider applying. In this talk we present a possible solution to this problem involving the use of objective multiple-choice sample interview questions. These questions are calibrated on current employees at Google who are members of Google's "Data Scientist - Research" job family. 

  

#### Speaker

_David Mease_  

to appear in unofficialgoogledatascience.com

david first began working at google in 2006, prior to that a professor at san jose state.
David works primarility on the hiring process for data science process


three data scientists, research, product, business
Motivation, technical skills needed for rols in industry are generally described using text
slide pic


lots of copy paste of job description which is challenging, the words cant mean that much. They know at google if they want to transfer
challenging for hiring, lots of people under the umbrellla of data science

our solution slide

what we did slide


---


Last talk was acutally by ark fange
Works on search

another model for growth measurement and prediction
Growth Dynamics Framework

background and problem
growth and account 

background slide

different mechanisms, for how users DAU behavior works

problem slide

HMM GDF Transition slide

growth slide

concepy measuring growth slide

case study
Can be business events, new products, kids starting school but framework figures out the buckets that contribute to MAU

Wjat if scnario planning, what would users look like if we improve retention by 1%, vs regular momentum. Or if we want to achieve a certain goal by next year, what retention improvements do we need overtime

There have been lots of testing of A/B Testing




